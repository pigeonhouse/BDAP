import org.apache.spark.ml.classification.LogisticRegression
import org.apache.spark.ml.feature.VectorAssembler

val userId = "%s"
val id = "%s"
val trainCol = "%s"
val label = "%s"
val newColName = "%s"
var df_ = df_%s

val all = trainCol + " " + label
val aimarray = all.split(" ")
val trainArray = trainCol.split(" ")

df_ = df_.select(aimarray.map(A => col(A)): _*)

val assembler = new VectorAssembler().setInputCols(trainArray).setOutputCol("features_lr")
df_ = assembler.transform(df_)

val predictions = Model_%s.transform(df_)
val predict_result = predictions.selectExpr("features_lr", label, s"round(prediction,1) as ${newColName}")

df_ = predict_result

val df_%s = predict_result

df_.write.format("parquet").mode(SaveMode.Overwrite).save(userId + "/" + id)

val fin = df_.limit(100).toJSON.collectAsList.toString

val colname = df_.columns
val fin_ = fin.substring(1, fin.length - 1)
val start = """{"colName":""""
val end = "\""
var json = colname.mkString(start,", ",end) + "}, "

json = "[" + json ++ fin_ + "]"